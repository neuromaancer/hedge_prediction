# Evaluation

This directory contains the code for evaluating the performance of the different models.

## Folder structure

- `evaluator.py`: The main evaluation script. It takes a model and a dataset as input and outputs the evaluation metrics.
- `clf_scores.py`: The script for evaluating the performance of the classification.
- `eval.py`: The script for evaluating from the command line.
- `ci.py`: The script for evaluating the confidence interval of the evaluation metrics.